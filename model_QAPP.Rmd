---
author: "Ryan Michie"
date: "`r format(Sys.Date(), '%m/%d/%Y')`"
output:
  word_document:
    reference_docx: N:/Status_and_Trend_Reports/Report_Files/Report_Template.docx
    keep_md: yes
    toc: yes
    fig_caption: yes
    fig_width: 12
    fig_height: 6
  html_document:
    toc: yes
    df_print: paged
---

---
title: "`r paste0("Modeling Quality Assurance Project Plan for the ", qapp_project_area, " Temperature Total Maximum Daily Load")`"
---

```{r, label=`setup`, include=FALSE}

options(knitr.duplicate.label = 'allow')
options(knitr.kable.NA = '')
options(tinytex.verbose = TRUE)

knitr::opts_chunk$set(results = "asis",
                      warning = FALSE,
                      error = FALSE,
                      message = FALSE,
                      autodep = TRUE)

library(knitr); library(kableExtra)
library(tidyverse)
library(captioner)
library(readxl)
library(lubridate)
library(flextable)
library(sf); library(sp)
library(rgdal)
library(ggplot2)
library(stringr)
library(english)
library(pacman)

tbls  <- captioner::captioner(prefix="Table")
figs <- captioner::captioner(prefix="Figure")
eqns <- captioner::captioner(prefix="Equation")

```

# Introduction

The North Umpqua Watershed includes several major drainages (rivers) that support salmonid spawning including: Little River, Rock Creek, Steamboat Creek and other major tributaries of the North Umpqua River that support salmonid spawning/rearing.  The beneficial uses that are affected by temperature are cold water aquatic salmonid use.  As required by law, the most sensitive beneficial uses were considered for listing.  The lower 68 river miles are on the 303(d) list for not attaining temperature criteria during fall spawning periods.  Elevated stream temperatures can place various salmonid life cycles at risk.  A TMDL was completed for the watershed for the salmonid rearing period, but a second TMDL needs to be developed to cover the spawning and egg incubation season.

# Problem Definition and Management Objectives

In 2007 the TMDL for the North Umpqua Subbasin was developed for bacteria, aquatic weeds, biological criteria and temperature. The original temperature TMDLs were based on the Natural Conditions Criteria (NCC) identified in Oregon Administrative Rules (OAR), specifically OAR 340-041-0028(8). These criteria were invalidated by the Oregon U.S. District Court. The applicable numeric and narrative temperature criteria must be used. As required by court order, the U.S. Environmental Protection Agency (USEPA) and State of Oregon (OR) are required to revise the water temperature TMDLs for the North Umpqua Subbasin. In revising the TMDLs the models used for the North Umpqua Subbasin mainstem will be updated to target the biologically-based numeric criteria (BBNC) and Human Use Allowance (HUA) WQS. The tributary segment TMDLs will also be updated with the BBNC and HUA WQS and a thermal load calculation.

The existing temperature TMDL addresses rearing/migration and spawning period temperature impairments on streams without point sources or dams for the entire basin. In rivers that have no point sources or dams, activities designed to improve summer stream temperatures are the same activities that will improve fall and winter temperatures. The nonpoint source load allocations are expressed as effective shade targets and apply year-round.

Furthermore, the existing temperature TMDL addresses streams with point sources and dams during the rearing/migration (i.e. non-spawning) time period. Waste load allocations have been developed for point sources during the portion of the year when spawning does not occur and will be incorporated into the NPDES permits. During the spawning period, there are three impaired segments on the North Umpqua River that are downstream of a hydro-electric project and a point source is present. More data and analysis are needed to complete those TMDLs. Likewise, on other streams and rivers that are not currently identified as impaired during the spawning period and have point sources or dams, the TMDLs were not computed.

This QAPP document provides the management context and information about existing models to be used for the TMDL revisions.

# Conceptual Model: Key Processes and Variables

Anthropogenic heat sources are derived from solar radiation as increased levels of sunlight reach the stream surface and effluent discharges to surface waters. Therefore, the pollutants targeted in the existing TMDL are: 

**Anthropogenic Nonpoint Sources**: Heat from human-caused solar radiation loading increases to the stream network, as a result of alterations in near stream vegetation, channel morphology, and flow modifications.

Historically, human activities have altered the stream morphology and hydrology and decreased the amount of riparian vegetation in the basin. The basin includes urban, agricultural, and forested lands. Additionally, hydroelectric projects and multiple points of diversion in the Umpqua River Basin have altered stream flow levels. 

Low summertime flows decrease the thermal assimilative capacity of streams. Pollutant (solar radiation) loading causes larger temperature increases in stream segments where flows are reduced by human uses. 

Larger streams, such as the North Umpqua Rivers naturally experience a large solar flux because their channels are too wide to be significantly shaded by riparian vegetation. Smaller tributaries, such as Little River, are easier to shade and have smaller background solar flux values. Additionally, effective shade levels on smaller streams are more sensitive to riparian disturbances and so the differences between current condition solar flux and background solar flux can be larger.

**Anthropogenic Point Sources**: Heat from warm water discharges of human origin, such as industrial outfalls, waste water treatment plants, and other point sources.

PacifiCorpâ€™s hydro electric project on the North Umpqua River is responsible for elevated stream temperatures between Lemolo Reservoir and the Umpqua River tidewater boundary. Several large diversions reduce flow volumes within the bypass reaches (the natural stream channel below the diversions). Small flow volumes are much more sensitive to solar heating and stream temperatures warm rapidly within the bypass reaches.

# Technical Approach

## Overview

Stream temperature TMDLs are generally scaled to a subbasin or basin and include all perennial surface waters that have salmonid presence or that contribute to areas with salmonid presence. Since stream temperatures are affected by cumulative interactions between upstream and local sources, the TMDL considers all surface waters that affect the temperatures of 303(d) listed waterbodies. For example, the `r subbasin` is water quality limited for temperature. To address this listing in the TMDL, all major tributaries are included in the TMDL analysis and TMDL allocations are applied throughout the entire stream network.

An important step in the TMDL is to perform a source assessment which quantifies the anthropogenic contributions to stream heating. One anthropogenic contribution to solar radiation heat loading results from decreased stream surface shade. Decreased stream shade may be caused by near stream vegetation disturbance/removal and channel morphology changes. Other anthropogenic sources of stream warming may include stream flow reductions and warm water point source effluent.

Heat is the identified pollutant. Anthropogenic nonpoint and point sources are not permitted to heat a waterbody more than 0.3 $^\circ C$ above the applicable criteria, cumulatively at the point of maximum impact. Allocated conditions are expressed as solar heat load and solar heat flux (watts, and watts per square meter, respectively). Nonpoint source heat allocations are translated into effective shade surrogate measures. Effective shade surrogate measures provide site-specific targets for land managers. Attainment of the surrogate measures ensures compliance with the nonpoint source allocations. Point source waste load allocations are based on the applicable numeric and/or narrative criteria. Point sources are not allowed to increase stream temperatures more than 0.1 $^\circ C$ (a portion of the 0.3 $^\circ C$ human use allowance) cumulatively at the point of maximum impact.

Stream temperatures were simulated using a computer model (Heat Source) for the main rivers and their larger tributaries. Simulations focus on the larger streams that contain or influence primary fish habitat. Site-specific load allocations have been developed for the streams that were simulated. Other streams are assigned generalized load allocations based on potential vegetation and effective.

## Model Selection

The modeling framework needs for this project include:

1)	Prediction of hourly stream temperatures over a period of months and at a no greater than 500 meter longitudinal resolution.  

2)	Prediction of hourly solar radiation flux and daily effective shade at a no greater than 50 meter longitudinal resolution.  

3)	Ability to evaluate hourly stream temperature response from changes in streamside vegetation within the upstream catchment.  

4)	Ability to evaluate hourly stream temperature response from changes in water withdrawals and tributary stream flow within the upstream catchment.  

5)	Ability to evaluate hourly stream temperature response from changes in channel morphology within the upstream catchment.  

6)	Ability to evaluate hourly stream temperature response from changes in effluent temperature and flow discharge from NPDES permitted facilities.  

7)	Prediction of hourly water temperatures in stratified reservoir systems along the North Umpqua River system over a period of months.  

8)	Ability to evaluate hourly stream and reservoir temperature response from changes in dam operations along the North Umpqua River System.  

For these reasons, the Heat Source stream thermodynamics model was selected for stream temperature simulation.  

# Data Availability and Quality

## Meteorology

```{r, label=`t51`, echo=FALSE}

if(NROW(model.input[which(model.input$`Model Location Type` == "Meteorological"),])>0){
  
  t51_sp <- model.input %>% 
    dplyr::filter(`Model Location Type` %in% c("Meteorological")) %>%
    dplyr::filter(!is.na(`Data Source`) & is.na(`Interpolated Data`)) %>%
    dplyr::mutate(Station = ifelse(`Station ID` == "No Station ID or unknown" | is.na(`Station ID`),
                                   `Data Source`,
                                   paste0(`Station ID`, ", ", `Data Source`)),
                  `Latitude/Longitude` = ifelse(is.na(Latitude), NA, paste0(round(Latitude,4), ", ",round(Longitude,3))),
                  `Available Data` = Parameter) %>% 
    dplyr::select(Station, `Latitude/Longitude`, `Available Data`) %>%
    dplyr::group_by(Station, `Latitude/Longitude`) %>% 
    dplyr::summarize(`Available Data` = toString(unique(sort(`Available Data`)))) %>% 
    dplyr::ungroup()
  
  if(NROW(t51_sp)>0){
    
    t51_sp_tbl <- knitr::kable(t51_sp, format = "pandoc", padding = 2,
                               caption = tbls(name = "t51_sp",
                                              caption = paste0("Meteorological stations and data available in public databases and DEQ files in the ", qapp_project_area, ".")))
    
  }
  
}

t51_ncdc <- ncdc.station.tbl %>% 
  dplyr::filter(!str_detect(station.id,"COOP")) %>% 
  dplyr::mutate(`Station` = name,
                `Station ID` = station.id,
                `Latitude/Longitude` = paste0(round(lat,4), ", ",round(long,3)),
                `Available Data` = Parameter) %>%
  dplyr::group_by(`Station`, `Station ID`, `Latitude/Longitude`, `Available Data`) %>% 
  dplyr::summarize(n=n()) %>%
  dplyr::ungroup() %>% 
  dplyr::select(`Station`, `Station ID`, `Latitude/Longitude`, `Available Data`) %>% 
  dplyr::arrange(`Station`, `Station ID`)

if(NROW(t51_ncdc)>0){
  
  t51_ncdc_tbl <- knitr::kable(t51_ncdc, format = "pandoc", padding = 2,
                               caption = tbls(name = "t51_ncdc",
                                              caption = paste0("Meteorological stations and data available in the National Climatic Data Center (NCDC) database in the ",
                                                               qapp_project_area, ".")))
}

t51_raws <- raws.station.tbl %>% 
  dplyr::mutate(`Station` = siteName,
                `Station wrccID` = wrccID,
                `Latitude/Longitude` = paste0(round(lat,4), ", ",round(long,3)),
                Agency = agency) %>% 
  dplyr::group_by(`Station`, `Station wrccID`, `Latitude/Longitude`, Agency) %>% 
  dplyr::summarize(n=n()) %>%
  dplyr::ungroup() %>%
  dplyr::select(`Station`, `Station wrccID`, `Latitude/Longitude`, Agency) %>% 
  dplyr::arrange(`Station`, `Station wrccID`)

if(NROW(t51_raws)>0){
  
  t51_raws_tbl <- knitr::kable(t51_raws, format = "pandoc", padding = 2,
                               caption = tbls(name = "t51_raws",
                                              caption = paste0("Meteorological stations and data, including ", knitr::combine_words(unique(sort(tolower(raws.station.tbl$Parameter)))), ", available in the Remote Automatic Weather Station (RAWS) database in the ", qapp_project_area, ".")))
  
}

t51_agrimet <- agrimet.station.tbl %>%
  dplyr::mutate(`Station` = description.x,
                `Station ID` = siteid,
                `Latitude/Longitude` = paste0(round(lat,4), ", ",round(long,3))) %>% 
  dplyr::group_by(`Station`, `Station ID`, `Latitude/Longitude`) %>% 
  dplyr::summarize(n=n()) %>%
  dplyr::ungroup() %>%
  dplyr::select(`Station`, `Station ID`, `Latitude/Longitude`) %>% 
  dplyr::arrange(`Station`, `Station ID`)

if(NROW(t51_agrimet)>0){
  
  t51_agrimet_tbl <- knitr::kable(t51_agrimet, format = "pandoc", padding = 2,
                                  caption = tbls(name = "t51_agrimet",
                                                 caption = paste0("Meteorological stations and data, including air temperature, precipitation, relative humidity and wind, available in the USBL AgriMet database in the ", qapp_project_area, ".")))
  
}

t51_hydromet <- hydromet.station.tbl %>% 
  dplyr::filter(Parameter %in% c("Air Temperature","Precipitation")) %>% 
  dplyr::mutate(`Station` = Station.Name,
                `Station ID` = Station.ID,
                `Latitude/Longitude` = paste0(round(as.numeric(Lat),4), ", ",round(as.numeric(Long),3)),
                `Available Data` = Parameter) %>% 
  dplyr::select(`Station`, `Station ID`, `Latitude/Longitude`, `Available Data`) %>%
  dplyr::group_by(`Station`, `Station ID`, `Latitude/Longitude`) %>% 
  dplyr::summarize(`Available Data` = toString(unique(sort(`Available Data`)))) %>% 
  dplyr::ungroup()

if(NROW(t51_hydromet)>0){
  
  t51_hydromet_tbl <- knitr::kable(t51_hydromet, format = "pandoc", padding = 2,
                                   caption = tbls(name = "t51_hydromet",
                                                  caption = paste0("Meteorological stations and data available in the USBL Hydromet database in the ", qapp_project_area, ".")))
  
}

t51_mw <- mw.station.tbl %>% 
  dplyr::mutate(`Station` = NAME,
                `Station ID` = STID,
                `Latitude/Longitude` = paste0(round(as.numeric(lat),4), ", ",round(as.numeric(long),3))) %>% 
  dplyr::group_by(`Station`, `Station ID`, `Latitude/Longitude`) %>% 
  dplyr::summarize(n=n()) %>%
  dplyr::ungroup() %>%
  dplyr::select(`Station`, `Station ID`, `Latitude/Longitude`) %>% 
  dplyr::arrange(`Station`, `Station ID`)

if(NROW(t51_mw)>0){
  
  t51_mw_tbl <- knitr::kable(t51_mw, format = "pandoc", padding = 2,
                             caption = tbls(name = "t51_mw",
                                            caption = paste0("Meteorological stations and data, including air temperature, precipitation, relative humidity, wind speed and wind direction, available in the MesoWest database in the ", qapp_project_area, ".")))
  
}

if(NROW(model.input[which(model.input$`Model Location Type` == "Meteorological"),])>0){
  
  tables.met <- data.frame(tbl_name = c("t51_sp","t51_ncdc","t51_raws","t51_agrimet","t51_hydromet","t51_mw"),
                           tbl_rows = c(NROW(t51_sp),NROW(t51_ncdc),NROW(t51_raws),NROW(t51_agrimet),NROW(t51_hydromet),NROW(t51_mw))) %>% 
    dplyr::filter(tbl_rows != "0")
  
  t51_num <- NROW(tables.met)
  
} else {
  
  tables.met <- data.frame(tbl_name = c("t51_ncdc","t51_raws","t51_agrimet","t51_hydromet","t51_mw"),
                           tbl_rows = c(NROW(t51_ncdc),NROW(t51_raws),NROW(t51_agrimet),NROW(t51_hydromet),NROW(t51_mw))) %>% 
    dplyr::filter(tbl_rows != "0")
  
  t51_num <- NROW(tables.met)
  
}

```

Meteorological data, including air temperature, cloudiness, relative humidity, and wind speed, are available from ODEQ database, NOAA National Climatic Data Center (NCDC), National Interagency Fire Center (NIFC) Remote Automatic Weather Stations (RAWS), Bureau of Reclamation Cooperative Agricultural Weather Network (AgriMet) and Automated Hydrologic and Meteorologic Monitoring Stations Network (Hydromet), and University of Utah MesoWest database. `r ifelse(NROW(model.input[which(model.input$"Model Location Type" == "Meteorological"),])>0,tbls(name = "t51_sp", display="cite"),tbls(name = "t51_ncdc", display="cite"))` - Table `r t51_num` list available meteorological data from these sources in the `r qapp_project_area`.

`r if(NROW(model.input[which(model.input$"Model Location Type" == "Meteorological"),])>0){t51_sp_tbl}`
`r if(NROW(t51_ncdc)>0){t51_ncdc_tbl}`
`r if(NROW(t51_raws)>0){t51_raws_tbl}`
`r if(NROW(t51_agrimet)>0){t51_agrimet_tbl}`
`r if(NROW(t51_hydromet)>0){t51_hydromet_tbl}`
`r if(NROW(t51_mw)>0){t51_mw_tbl}`

## Thermal Infrared (TIR) Data

```{r, label=`t52`, echo=FALSE}

t52 <- model.input %>% 
  dplyr::filter(`Station ID` == "TIR") %>% 
  dplyr::rename(`Abbreviated Reference` = `Data Source`) %>% 
  dplyr::left_join(ref, by = "Abbreviated Reference") %>% 
  dplyr::mutate(`Abbreviated Reference` = strip_alpha(`Abbreviated Reference`)) %>% 
  dplyr::mutate(Reference = paste(`Full Reference`, ifelse(is.na(`Reference Link`),"",`Reference Link`)))

waterbodies <- unique(sort(t52$`Model Waterbody`))

citations <- unique(sort(t52$`Abbreviated Reference`))

```

ODEQ contracted with Watershed Sciences, Inc. to provide airborne thermal infrared (TIR) imagery of spatial temperature patterns within the `r qapp_project_area`. TIR data were used to characterize the thermal regime of the streams and habitat quality in the basin where the TIR data were available.

`r paste0("TIR data are available for ", knitr::combine_words(waterbodies), " (", knitr::combine_words(citations), ").")`

## Continuous Stream Temperature Data

```{r, label=`t53`, echo=FALSE}

st_awqms <- station_awqms %>% 
  dplyr::rename(`Station Description` = StationDes,
                Organization = OrgID,
                Latitude = Lat_DD,
                Longitude = Long_DD) %>% 
  dplyr::select(`Station Description`,`Station ID`, Organization, Latitude, Longitude)

st_model <- station_model %>% 
  dplyr::filter(`Parameter` %in%  c("Water Temperature")) %>% 
  dplyr::filter(!is.na(`Data Source`) & is.na(`Interpolated Data`)) %>% 
  dplyr::mutate(`Station Description` = ifelse(is.na(StationDes),`Model Location Name`,StationDes),
                Organization = ifelse(is.na(OrgID),`Data Source`,OrgID)) %>% 
  dplyr::select(`Station Description`,`Station ID`, Organization, Latitude, Longitude)

t53_1 <- rbind(st_awqms,st_model) %>% 
  dplyr::filter(!`Station ID` == "TIR") %>% 
  dplyr::mutate(`Station Name and ID` = ifelse(`Station ID` == "No Station ID or unknown" | is.na(`Station ID`),
                                               `Station Description`,
                                               paste0(`Station Description`, " (", `Station ID`, ")"))) %>% 
  dplyr::mutate(`Latitude/Longitude` = ifelse(is.na(Latitude), NA, paste0(round(Latitude,4), ", ",round(Longitude,3)))) %>% 
  dplyr::mutate(`Station Name and ID` = stringr::str_to_title(`Station Name and ID`)) %>% 
  dplyr::mutate_at("Station Name and ID", str_replace_all, "Ordeq", "ORDEQ") %>%
  dplyr::mutate_at("Station Name and ID", str_replace_all, " Rm", " RM") %>%
  dplyr::mutate_at("Station Name and ID", str_replace_all, "Lb", "LB") %>%
  dplyr::mutate_at("Station Name and ID", str_replace_all, "Nf", "NF") %>%
  dplyr::mutate_at("Station Name and ID", str_replace_all, "Sf", "SF") %>%
  dplyr::distinct(`Station Name and ID`, .keep_all=TRUE) %>%
  dplyr::mutate(Organization = ifelse(Organization == "OregonDEQ", "ODEQ", Organization)) %>% 
  dplyr::mutate(Organization = ifelse(Organization == "11NPSWRD_WQX", "EPA WQX", Organization)) %>% 
  dplyr::select(`Station Name and ID`,`Latitude/Longitude`, Organization) %>% 
  dplyr::arrange(`Station Name and ID`)

if(NROW(t53_1)>0){
  
  t53_1_tbl <-  knitr::kable(t53_1, format = "pandoc", padding = 2,
                             caption = tbls(name = "t53_1",
                                            caption = paste0("Continuous temperature monitoring stations in the ", qapp_project_area, " currently available in public databases and DEQ files.")))
  
}

t53_2 <- data.sample.count %>%
  dplyr::filter(!`Station ID` == "TIR") %>% 
  dplyr::mutate(`Station Name and ID` = ifelse(`Station ID` == "No Station ID or unknown" | is.na(`Station ID`),
                                               StationDes,
                                               paste0(StationDes, " (", `Station ID`, ")"))) %>% 
  dplyr::select(Year, `Station Name and ID`, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec) %>% 
  dplyr::arrange(Year, `Station Name and ID`)

if(NROW(t53_2)>0){
  
  t53_2_tbl <- knitr::kable(t53_2, format = "pandoc", padding = 2,
                            caption = tbls(name = "t53_2",
                                           caption = paste0("Summary of existing temperature data in the ", qapp_project_area,". Columns Jan â€“ Dec indicate the number of daily maximum temperature results in each month.")))
  
}


```

All available continuous stream temperature data were retrieved from DEQâ€™s Ambient Water Quality Monitoring System (AWQMS). `r tbls(name = "t53_1", display="cite")` list all the locations where continuous stream temperature data were collected and the organizations that collected that data. `r tbls(name = "t53_2", display="cite")` summarizes when data were collected at each station.

`r t53_1_tbl`
`r t53_2_tbl`

## Stream Flow Data

```{r, label=`t54`, echo=FALSE}

t54_usgs <- usgs.station.tbl %>% 
  dplyr::mutate(Station = station_nm,
                `Station ID`= site_no,
                `Latitude/Longitude` = paste0(round(dec_lat_va,4), ", ",round(dec_long_va,3))) %>% 
  dplyr::select(Station, `Station ID`, `Latitude/Longitude`) %>% 
  dplyr::arrange(Station)

t54_hydromet <- hydromet.station.tbl %>% 
  dplyr::filter(Parameter %in% c("Discharge", "Spillway Discharge", "Flow")) %>% 
  dplyr::distinct(Lat, Long, .keep_all = TRUE) %>% 
  dplyr::mutate(Station = Station.Name,
                `Station ID` = Station.ID,
                `Latitude/Longitude` = paste0(round(as.numeric(Lat),4), ", ",round(as.numeric(Long),3))) %>% 
  dplyr::select(Station, `Station ID`, `Latitude/Longitude`) %>% 
  dplyr::arrange(Station)

t54_sp <- model.input %>% 
  dplyr::filter(`Parameter` %in% c("Flow")) %>%
  dplyr::filter(!`Data Source` == "USGS" & is.na(`Interpolated Data`)) %>% 
  dplyr::distinct(Latitude, Longitude, .keep_all = TRUE) %>% 
  dplyr::mutate(Station = `Model Location Name`,
                `Latitude/Longitude` = ifelse(is.na(Latitude), NA, paste0(Latitude, ", ", Longitude))) %>% 
  dplyr::select(Station, `Station ID`, `Latitude/Longitude`, `Data Source`) %>% 
  dplyr::arrange(Station)

if(NROW(t54_usgs)>0){
  
  t54_usgs_tbl <- knitr::kable(t54_usgs, format = "pandoc", padding = 2,
                               caption = tbls(name = "t54_usgs",
                                              caption = paste0("Continuous flow measurements available from the USGS flow gaging stations in the ", qapp_project_area, ".")))
  
}

if(NROW(t54_hydromet)>0){
  
  t54_hydromet_tbl <- knitr::kable(t54_hydromet, format = "pandoc", padding = 2,
                                   caption = tbls(name = "t54_hydromet",
                                                  caption = paste0("Continuous flow measurements available from the USBR Hydromet monitoring stations in the ", qapp_project_area, ".")))
  
}

if(NROW(t54_sp)>0){
  
  t54_sp_tbl <- knitr::kable(t54_sp, format = "pandoc", padding = 2,
                             caption = tbls(name = "t54_sp",
                                            caption = paste0("Flow measurements from ODEQ and other public databases in the ", qapp_project_area, ".")))
  
  t54.sp.tbl.num <- tbls(name = "t54_sp", display="cite")
  
}

```

`r tbls(name = "t54_usgs", display="cite")` - `r tbls(name = "t54_sp", display="cite")` list the stations for flow volume data and other instream measurements that were available in USGS, Oregon DEQ, and other public databases.

`r t54_usgs_tbl`
`r t54_hydromet_tbl`
`r t54_sp_tbl`

## Point Source Discharges

```{r, label=`t55`, echo=FALSE}

section.npdes.ind <- npdes.ind %>% 
  dplyr::filter(`Project Area` %in%  qapp_project_area) %>%
  dplyr::mutate(`Common Name` = stringr::str_to_title(`Common Name`)) %>%
  dplyr::mutate_at("Common Name", str_replace_all, "Stp", "STP") %>%
  dplyr::mutate(`Facility Name and Number` = paste0(`Common Name`," (", `WQ File Nbr`,")"),
                `Latitude/Longitude` = paste0(round(Latitude,4), ", ",round(Longitude,3)),
                `Permit Type and Description` = paste0(`Permit Type`, ": ", `Permit Description`),
                `Stream/River Mile` = ifelse(is.na(`Stream Name`), NA, paste0(`Stream Name`, " ", " RM ",`River Mile`))) %>% 
  dplyr::select(`Facility Name and Number`, `Latitude/Longitude`,`Permit Type and Description`, `Stream/River Mile`) %>% 
  dplyr::arrange(`Facility Name and Number`)

if(NROW(section.npdes.ind)>0){
  
  t55_ind_tbl <- knitr::kable(section.npdes.ind, format = "pandoc", padding = 2,
                              caption = tbls(name = "t55_ind",
                                             caption = paste0("Summary of individual NPDES permitted discharges on ", qapp_project_area, ".")))
  
}

section.npdes.gen <- npdes.gen %>% 
  dplyr::filter(`Project Area` %in%  qapp_project_area)%>%
  dplyr::mutate(`Permit Type and Description` = paste0(PermitType, ": ", PermitDescription)) %>% 
  dplyr::group_by(`Permit Type and Description`) %>% 
  dplyr::summarise(`Number of Permits` = n()) %>% 
  dplyr::ungroup()

if(NROW(section.npdes.gen)>0){
  
  t55_gen_tbl <- knitr::kable(section.npdes.gen, format = "pandoc", padding = 2,
                              caption = tbls(name = "t55_gen",
                                             caption = paste0("Summary of general NPDES permitting types in the ", qapp_project_area, ".")))
  
}

```

`r tbls(name = "t55_ind", display="cite")` identifies all the active individual NPDES permittees in the `r qapp_project_area`. Many of these permittees submit Discharge Monitoring Reports (DMRs) as a condition of their permit. Depending on the monitoring requirements in the permit, some permittees are required to report effluent temperature and effluent flow rates in the DMR. The frequency and type of reporting varies by permit and permit type. Some permits only require monthly, weekly, or daily grab samples while others require summary statistics such as daily maximum, daily mean, or seven day average daily maximum. When possible, DEQ will utilize any continuous effluent data that has been provided to DEQ. When continuous data is not available, DMR data will be utilized to characterize point source discharges. `r tbls(name = "t55_gen", display="cite")` lists all the active general NPDES permitting types in the `r qapp_project_area`.

`r t55_ind_tbl`
`r if(NROW(section.npdes.gen)>0){t55_gen_tbl}`

## Effective Shade Measurements

```{r, label=`t56`, echo=FALSE}

t56 <- model.input %>% 
  dplyr::filter(`Parameter` %in% c("Effective Shade")) %>% 
  dplyr::filter(is.na(`Interpolated Data`)) %>% 
  dplyr::distinct(Latitude, Longitude, .keep_all = TRUE) %>% 
  dplyr::mutate(Station = `Model Location Name`,
                `Latitude/Longitude` = ifelse(is.na(Latitude), NA, paste0(Latitude, ", ", Longitude))) %>% 
  dplyr::select(Station, `Station ID`, `Latitude/Longitude`, `Data Source`)

if(NROW(t56)>0){
  
  t56_tbl <- knitr::kable(t56, format = "pandoc", padding = 2,
                          caption = tbls(name = "t56",
                                         caption = paste0("Effective shade data collected in the  ", qapp_project_area, ".")))
  
}

```

`r tbls(name = "t56", display="cite")` lists the stations for effective shade measurements that were available in the public and Oregon DEQ databases.

`r t56_tbl`

# Model Development and Calibration

```{r, label=`chap6`, include=FALSE}

chap6 <- NULL

for(waterbody_name in unique(sort(model.info$`Model Waterbody`))){
  
  chap6 <- c(chap6, knitr::knit_child(input = "chap6.Rmd", envir = globalenv()))
  
}

```

`r paste(chap6, collapse = "\n")`

# Model Evaluation and Acceptance

## Model Uncertainty and Sensitivity

As with any mathematical approximation of reality, a water quality model is subject to significant uncertainties. Direct information on the aggregate prediction uncertainty will arise from the model validation exercise; however, further diagnostics are needed to understand the sources and implications of uncertainty.

The major sources of model uncertainty include the mathematical formulation, boundary conditions data uncertainty, uncertainty in spatial representation (e.g., bathymetry), calibration data uncertainty, and parameter specification. In many cases, a significant amount of the overall prediction uncertainty is due to boundary conditions (e.g., uncertainty in estimation of ungaged tributary flows) and uncertainty in the observed data used for calibration and validation. These sources of uncertainty are largely unavoidable, but do not invalidate the use of the model for decision purposes. Uncertainties in the mathematical formulation and model parameters are usually of greater concern for decision purposes as these describe the cause and effect relationships in the calibrated model. 

The existing `r subbasin` mainstem and tributary models were extensively evaluated to determine uncertainty in the model equations as well as data used for boundary inputs. A discussion of the methodology used to evaluate uncertainty is found in *Appendix 2: Stream Temperature TMDL Supplemental Information of the 2006 Umpqua Basin TMDL* (citation). No additional sensitivity or uncertainty analyses will be performed on the revised Heat Source models. Additional temperature variability analyses will be conducted to evaluate the range of natural thermal conditions and how they may influence stream temperature. It is anticipated that these analyses will be approved iteratively through QAPP addenda.

## Model Acceptance

For a model to be utilized in the development of TMDLs, the model must first be accepted by the regulatory agencies and stakeholders. The most common model development goals are (1) to minimize the difference between simulated and observed water quality and (2) to capture the spatial and temporal patterns in the observed water quality conditions. Progress toward achieving these goals is commonly captured in error statistics and graphical plots. However, model quality goes beyond these core evaluations. Several parallel tasks to achieve overall model quality are pursued alongside efforts to reduce model error, including:

1)	Incorporation of all available observations of the system (e.g., geometry, flow, boundary inputs/withdrawals, and meteorology) for the time period simulated.  

2)	Reasonable estimation methods and assumptions to fill gaps in the observations.  

3)	Calibration of model parameters and unmeasured boundary conditions within reasonable bounds to improve agreement between simulated and observed water quality.  

4)	Identification of key parameters/processes through model calibration and sensitivity analysis.  

5)	Clear communication of key assumptions during model development with the project team.  

6)	Clear written documentation of all important elements in the model, including model setup, boundary conditions, assumptions, and known areas of uncertainty.  

7)	Peer review.

The intended use of the revised Heat Source models is to focus on the ability to understand and quantify the contribution of heat inputs and operational methodology on water temperature. As such, the abilities of the models to replicate observed water temperature concentrations and to represent the relative contributions of different stressor sources are of greatest importance. Ideally, the models should attain tight calibration to observed data; however, a less precise calibration can still provide useful information.

Error statistics were calculated for each calibrated model.  Below are the equations used for each type of error statistic.

Mean Error: $ME = \frac{1}{n}\sum(X_{sim} - X_{obs})$

Mean Absolute Error: $MAE = \frac{1}{n}\sum|X_{sim} - X_{obs}|$

Root Mean Square Error: $RMSE = \sqrt{\frac{1}{n}\sum(X_{sim} - X_{obs})^2}$

Nash-Sutcliffe efficiency coefficient: $NS = 1 - \frac {\sum (X_{sim} - X_{obs})^2}{\sum (X_{sim} - \overline{X_{obs}})^2}$

where,  
$X_{sim}$ = The simulated temperature;  
$X_{obs}$ = The observed or measured temperature;  
$\overline X_{obs}$ = The mean of the observed or measured temperature;  
$n$ = The sample size.

# Documentation in Model Reports

Model updates, setup, and results for the TMDL Revisions will be documented in a technical memorandum that will be provided after model work has been completed. The document will outline updates to the models as well as the analyses performed for the tributaries or sources. Tetra Tech will deliver the Draft Technical Memorandum for USEPA and DEQ to review and provide comments. Tetra Tech will update the memorandum based on the USEPA and DEQ comments and submit a Final Technical Memorandum. 

The Tetra Tech Project Manager will maintain a central project file in Tetra Techâ€™s Fairfax, Virginia office to contain all related documents, reports, communications, data compilations, checklists or other records, and deliverables (electronic files and hard copies). Electronic files and records will be stored on Tetra Techâ€™s secure network, which is regularly backed up internally, and to an off-site server to preserve business continuity in the event of natural or other catastrophic events, which may result in local or regional catastrophic failure or disruption. The Project Manager will retain all files for a period of no less than five years after final delivery.

# Peer Review

Peer review of the models and model results will be conducted in the following ways:

DEQ will conduct internal peer review during the modeling process with input from EPA Region 10 as needed.

DEQ will consider feedback on model scenarios and results from the TMDL advisory group and make changes as appropriate.

DEQ will, review and respond to any public comments received on the model and model results, and make changes as appropriate.

# Management Scenarios

Management scenarios described in this section summarize means by which the current conditions and possible alternatives will be evaluated. Some or all of these scenarios will be executed and assessed in the modeling.

## Scenario Definitions

### Current Conditions
This scenario evaluates stream temperature warming or cooling from existing conditions.

### Restored Vegetation
This scenario evaluates stream temperature warming or cooling contributed by removal of streamside vegetation. This scenario will be compared to the current condition model. Elements of this scenario include:

*	Restoring streamside vegetation in areas along the model extent to minimize anthropogenic loading of solar radiation.

*	Restoration areas are locations along the model extent that are currently characterized as disturbed or have bare ground, grass, or small shrubs (defined as <= 0.9 meters or 3 feet in height in Heat Source). The management strategy applied in these areas is to restore the vegetation. The restored vegetation type, height, density, and overhang used for Heat Source will be identified during the TMDL process.

*	Model inputs for land cover height, density, and overhang will be modified to reflect the restored areas.

*	Heat Source model boundary inputs for stream temperature will be modified to reflect the monthly mean daily maximum and minimum stream temperature changes from restoring disturbed areas modeled in the SSN models. 

*	All other model inputs will be the same as the current calibrated model.

### Protected Vegetation

This scenario evaluates stream temperature warming or cooling that would occur if existing vegetation is removed. This scenario will be compared to the current condition model. Elements of this scenario include:

*	Protecting existing streamside vegetation and actively managing it to a mature stand in order limit new anthropogenic loading of solar radiation.

*	Protection areas are locations along the model extent with some existing streamside vegetation, such as medium to tall trees. The exact definition will be determined during the TMDL process. Existing streamside vegetation in protection areas will be removed to evaluate the stream warming from the existing trees.

*	Model inputs for land cover height, density, and overhang will be set to zero in protection areas.

*	Heat Source model boundary inputs for stream temperature will be modified to reflect the monthly mean daily maximum and minimum stream temperature changes from removing vegetated areas modeled in the SSN models. 

*	All other model inputs will be the same as the current calibrated model.

### Restored Stream Flow

This scenario evaluates stream temperature warming or cooling from keeping permitted water withdrawals as instream flow. This scenario will be compared to the current conditions model scenario. Elements of this scenario include:

*	Maintaining all currently permitted water withdrawals as instream flow in order to increase the thermal loading capacity and reduce stream warming.

*	Model boundary and tributary flows will be set to reflect the additional instream flows.

*	All other model inputs will be the same as the current calibrated model.

### Channel Morphology
This scenario evaluates stream temperature warming or cooling from improvements to channel morphology, including projects to restore cold water refuges. This scenario will be compared to the current conditions model scenario. Elements of this scenario include:

* Modifying channel width and/or depth to reflect locations where improvements to channel morphology are needed. The location of channel morphology projects will be determine during the TMDL process.

* Model inputs for bottom width, channel angle z, manningâ€™s n, gradient, elevation, porosity, percent hyporheic flow, hyporheic zone thickness, land cover height, density, and overhang may be modified in areas with improved channel morphology.

* All other model inputs will be the same as the current calibrated model.

### TMDL Implementation Plans

This scenario evaluates stream temperature warming or cooling from proposed or existing DMA TMDL implementation plans. These scenarios will be compared to the non-anthropogenic model scenario. Elements of this scenario include:

* Modifying streamside vegetation, instream flow, and/or channel morphology to reflect the proposed or existing DMA implementation plan. Translating the plan elements to the modeled landscape conditions will be determined during the TMDL process.

* Model inputs for land cover height, density, overhang, boundary condition flow and temperature, bottom width, channel angle z, manningâ€™s n, porosity, percent hyporheic flow, and hyporheic zone thickness, may be modified.

* All other model inputs will be the same as the current calibrated model.

### TMDL Waste Load Allocations

This scenario evaluates stream temperature warming or cooling from proposed or existing TMDL Waste Load Allocations. These scenarios will be compared to the non-anthropogenic model scenario. Elements of this scenario include:

* Modifying point source discharges to reflect proposed or existing TMDL Waste Load Allocations. 

* All other model inputs will be the same as the current calibrated model.

### Tributary Temperature
This scenario evaluates stream temperature warming or cooling from tributaries by modifying tributary temperature. This scenario will be compared to the current conditions model scenario. Elements of this scenario include:

* Tributary temperatures will be set to reflect potential conditions.

* All other model inputs will be the same as the current calibrated model.

### Climate

This scenario evaluates stream temperature warming or cooling from changes in climate. This scenario will be compared to the current conditions model scenario. Elements of this scenario include:

* Model inputs for air temperature, humidity and wind speed may be modified to reflect potential conditions or climate change scenarios.

* Model inputs for air temperature, humidity and wind speed may be modified to reflect historic climate change that has influenced current conditions. 

* All other model inputs will be the same as the current calibrated model.

### Point Sources

This scenario evaluates stream temperature warming or cooling from permitted point sources. This scenario will be compared to the current conditions model scenario. Elements of this scenario include:

* Removal of all point sources of pollutants.

* All other model inputs will be the same as the current calibrated model.

### Background

This scenario evaluates if the stream can achieve the applicable BBNC criteria and what the stream warming or cooling is from multiple anthropogenic activities. This scenario essentially combines the scenarios evaluating restored streamside vegetation, protecting existing vegetation, restoring instream flows, and making improvements to channel morphology. This scenario will be compared to the current conditions model scenario. 

```{r, label=`scenarios`, echo=FALSE}

for(waterbody_name in unique(sort(model.info$"Model Waterbody"))) {
  
  cat(paste0("## ", waterbody_name))
  cat("\n")
  
}

```


# Project Organization

## Project Team/Roles

```{r, label=`roles`, echo=FALSE}

roles <- readxl::read_xlsx("T:/Temperature_TMDL_Revisions/model_QAPPs/R/data/roles.xlsx",
                           sheet = "roles")

troles <- flextable::regulartable(roles) %>% 
  flextable::set_table_properties(layout = "autofit") %>% 
  flextable::merge_h(i = c(1,13)) %>% 
  flextable::bold(i = c(1,13)) %>% 
  flextable::bg(i = 1, bg = "#B52222", part = "body") %>% 
  flextable::valign(valign = "top") %>% 
  flextable::theme_box() %>% 
  flextable::set_caption(tbls(name = paste0("roles"),
                              caption = paste0("The roles and responsibilities of each team member involved in the temperature TMDL replacement project.")))

troles

```

## Expertise and Special Training Requirements

Tetra Tech staff involved in developing model input data sets and model application have experience in numerical modeling gained through their work on numerous similar projects. The Tetra Tech Project Manager, Jayshika Ramrakha, who has extensive experience managing similar projects, will provide project oversight. The Project Manager will ensure strict adherence to the project protocols.

Additional expertise or special training is not necessary at this time.

## Reports to Management

The DEQ Project Manager (or designee) will provide monthly progress reports to USEPA. As appropriate, these reports will inform USEPA of the following:

* Adherence to project schedule and budget
* Deviations from approved QAPP, as determined from project assessment and oversight activities
* The impact of any deviations on model application quality and uncertainty
* The need for and results of response actions to correct any deviations
* Potential uncertainties in decisions based on model predictions and data
* Data quality assessment findings regarding model input data and model outputs

## Project Schedule

The schedule for the initial phase of `r subbasin` Temperature TMDL Revisions is detailed ???Where?? and extends though ???When??. Under the court order, the revised TMDL must be approved by August 30, 2024. Given the need for USEPA review, public notice, comments, and responses, it is estimated the the modeling analysis and associated documentation must be completed by April 2024. A detailed project schedule will be developed as part of the Technical Direction for the next phase(s) of the project.

# Data Management

Tetra Tech will not conduct sampling (primary data collection) for this task. Secondary data collected as part of this task will be maintained as hardcopy only, both hardcopy and electronic, or electronic only, depending on their nature. All electronic data will be maintained on Tetra Techâ€™s computers and servers. Tetra Techâ€™s computers are either covered by on-site service agreements or serviced by in-house specialists. When a problem with a microcomputer occurs, in-house computer specialists diagnose the problem and correct it if possible. When outside assistance is necessary, the computer specialists call the appropriate vendor. For other computer equipment requiring outside repair and not covered by a service contract, local computer service companies are used on a time-and-materials basis. Routine maintenance of microcomputers is performed by in-house computer specialists. Electric power to each microcomputer flows through a surge suppressor to protect electronic components from potentially damaging voltage spikes. All computer users have been instructed on the importance of routinely archiving work assignment data files from hard drive to compact disc or server storage. The office network server is backed up on tape nightly during the week. Screening for viruses on electronic files loaded on microcomputers or the network is standard company policy. Automated screening systems have been placed on all Tetra Tech computer systems and are updated regularly to ensure that viruses are identified and destroyed. Annual maintenance of software is performed to keep up with evolutionary changes in computer storage, media, and programs.

# Recordkeeping and Archiving

Thorough documentation of all modeling activities is necessary to be able to effectively interpret the results. All records and documents relevant to the application, including electronic versions of data and input data sets, will be maintained at Tetra Techâ€™s offices in the central file. Tetra Tech will deliver a copy of the records and documents in the central file to USEPA at the end of the task. Unless other arrangements are made, records will be maintained at Tetra Techâ€™s offices for a minimum of 3 years following task completion.

The Tetra Tech Project Manager and designees will maintain files, as appropriate, as repositories for information and data used in models and for preparing reports and documents during the task. Electronic project files are maintained on network computers and are backed up weekly. The Tetra Tech Project Manager will supervise the use of materials in the central files. The following information will be included in the hard copy or electronic task files in the central file:

* Any reports and documents prepared
* Contract and task order information
* QAPP and draft and final versions of requirements and design documents
* Electronic copies of models
* Results of technical reviews, internal and external design tests, quality assessments of output data, and audits
* Documentation of response actions during the task to correct problems
* Input and test data sets
* Communications (memoranda; internal notes; telephone conversation records; letters; meeting minutes; and all written correspondence among the task team personnel, suppliers, or others)
* Studies, reports, documents, and newspaper articles pertaining to the task
* Special data compilations

Records of receipt with information on source and description of documentation will be filed along with the original data sheets and files to ensure traceability. Records of actions and subsequent findings will be kept during additional data processing.

All data files, source codes, and executable versions of the computer software will be retained for internal peer review, auditing, or post-task reuse in the electronic task files in the administrative record. These materials include the following:

* Versions of the source and executable code used
* Databases used for model input, as necessary
* Key assumptions
* Documentation of the model code and verification testing for newly developed codes or modifications to the existing model

The Tetra Tech Modeling QC Officer and other experienced technical staff will review the materials listed above during internal peer review of modified existing models or new codes or models. The designated QC Officers will perform QC checks on any modifications to the source code used in the design process. All new input and output files, together with existing files, records, codes, and data sets, will be saved for inspection and possible reuse.

# QAPP Review and Approval

The DEQ Project Manager will lead distribution of the draft QAPP to their respective project teams. Comments from USEPA, Tetra Tech, and relevant reviewers will be provided to the Project Manager for further discussion if appropriate, and revision and submittal of the final plan within 10 business days of receipt of comments. Following USEPA approval, the Project Manager will distribute the final, signed copy to their respective staff assigned to the project. Official copies of the final, approved QAPP will be retained. If any change(s) in the QAPP are required during the project, they must be described in a memorandum and approved by the signatories to this QAPP and attached to the QAPP.

# Implementation and Adaptive Management

Due to the complexity of model development, some elements of the project might not proceed according to plan. Should an obstacle arise that requires a change in approach, Tetra Tech, in consultation with the project team, will return to the QAPP as a topic template for evaluating the effects on other aspects of the project. Tetra Tech will update the QAPP as needed through revisions or addenda, as model development proceeds and new aspects of the system are understood. Significant changes in technical approach would be described in the updated QAPP and would be reviewed by the project team listed on the QAPP approval page prior to implementation.

# References

```{r, label=`qapp_ref`, echo=FALSE}

tmdl.ref <- model.info %>% 
  dplyr::filter(`QAPP Project Area` %in% qapp_project_area) %>% 
  dplyr::distinct(`TMDL Document`, `Abbreviated Reference`) %>% 
  dplyr::left_join(ref, by = "Abbreviated Reference") %>% 
  dplyr::mutate(`Abbreviated Reference` = strip_alpha(`Abbreviated Reference`)) %>% 
  dplyr::mutate(reference = paste(`Full Reference`, ifelse(is.na(`Reference Link`),"",`Reference Link`))) %>% 
  dplyr::select(reference)


tir.ref <- data.frame(unique(sort(t52$Reference))) %>% 
  dplyr::rename(reference = "unique.sort.t52.Reference..")

qapp.ref <- rbind(tmdl.ref,tir.ref)

for(r in unique(sort(qapp.ref$reference))) {
  
  cat(paste0(r,"    "))
  cat("\
  
      ")
  cat("\n")
  
}

```

